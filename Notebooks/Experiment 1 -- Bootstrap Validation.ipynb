{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import os\n",
    "from collections import namedtuple\n",
    "\n",
    "import luigi\n",
    "import dill\n",
    "import numpy as np\n",
    "from scipy.stats import binom\n",
    "\n",
    "from experiment_framework.helpers import AllAsymptotics, \\\n",
    "load_completed_AAs_into_dataframe, load_completed_CCCs_into_dataframe\n",
    "from empirical_privacy import one_bit_sum, config\n",
    "from experiment_framework.asymptotic_analysis import compute_bootstrapped_upper_bound\n",
    "\n",
    "from notebook_context import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1\n",
    "p = 0.60\n",
    "ds = {\n",
    "    'n_trials': n, 'prob_success': p, 'gen_distr_type': 'multidim_binom',\n",
    "}\n",
    "asys = {\n",
    "    'gen_sample_kwargs'  : {'generate_in_batch': True,\n",
    "                            'x_concatenator': 'numpy.vstack'\n",
    "                           },\n",
    "    'fitter'             : 'knn',\n",
    "    # we use random tie-breaking since the samples are discrete\n",
    "    'fitter_kwargs'      : {'neighbor_method': 'gyorfi'},\n",
    "    'n_docs'                : 50,\n",
    "    'n_trials_per_training_set_size': 15,\n",
    "    'n_max'              : 2**13,\n",
    "    'validation_set_size': 2**10,\n",
    "    'p'                  : 0.9,  # for bootstrap\n",
    "    't'                  : 0.001  # for bootstrap\n",
    "}\n",
    "\n",
    "All = AllAsymptotics(\n",
    "        gen_sample_path='empirical_privacy.one_bit_sum.GenSampleOneBitSum',\n",
    "        dataset_settings=ds,\n",
    "        asymptotic_settings=asys)\n",
    "CCCs = [AA.requires()['CCC'] for AA in All.requires()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment to delete outputs and dependencies to re-run the experiments\n",
    "# for AA in All.requires():\n",
    "#     AA.delete_outputs()\n",
    "#     AA.delete_deps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "luigi.build([All], local_scheduler=True, workers=16, log_level='ERROR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AAs = All.requires()\n",
    "DF = load_completed_AAs_into_dataframe(AAs)\n",
    "n_docs = DF.doc_ind.nunique()\n",
    "DF = DF[DF.n_max==DF.n_max.max()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Compute $P(Correct)$ based on stat dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import comb\n",
    "def multidim_binom_stat_dist(p, d):\n",
    "    q = 1-p\n",
    "    n_combos = 2**d\n",
    "    stat_dist = 0\n",
    "    for k in range(d+1):\n",
    "        n_combos_with_k = comb(d, k)\n",
    "        p_1 = n_combos_with_k * p**k * q**(d-k)\n",
    "        p_2 = n_combos_with_k * q**k * p**(d-k)\n",
    "        delta_prob = np.abs(p_1 - p_2)\n",
    "        stat_dist += delta_prob\n",
    "    return 0.5*stat_dist\n",
    "        \n",
    "\n",
    "pc = 0.5+0.5*multidim_binom_stat_dist(p, 3)\n",
    "print(pc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF[DF['upper_bound']>=pc].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot outcomes for all trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configure_plotting_for_publication()\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.optimize import least_squares\n",
    "\n",
    "\n",
    "from experiment_framework.asymptotic_analysis import hoeffding_n_given_t_and_p, bootstrap_ci,\\\n",
    "    asymptotic_privacy_lr, transform_n_to_k_for_knn, asymptotic_curve\n",
    "from experiment_framework.privacy_estimator_mixins import get_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ax = DF.upper_bound.plot(kind='hist', bins=30)\n",
    "true_ub = pc\n",
    "plt.axvline(x=true_ub, color='r')\n",
    "plt.text(x=true_ub,\n",
    "         y=0.9,\n",
    "         s='$C_\\infty^*$ = {:.3f}'.format(true_ub),\n",
    "         transform=x_data_y_axis(),\n",
    "         horizontalalignment='center',\n",
    "         bbox=dict(facecolor='w', edgecolor='r', boxstyle='round')\n",
    "        )\n",
    "plt.xlabel('Upper Bound on $P[$Correct$]$')\n",
    "plt.title('Distribution of Upper Bounds over {ntri} trials with d={d} p={p}'.format(\n",
    "    ntri=asys['n_docs'],\n",
    "    d=3,\n",
    "    p=p\n",
    "))\n",
    "\n",
    "if SAVE_FIGURES_FOR_LATEX:\n",
    "    plt.title('')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.xlabel('Estimated Upper Bound on $C^*_\\infty$')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(FIGURES_PATH, 'experiment_1_upper_bound_histogram.eps'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the details for a single trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DFccc = load_completed_CCCs_into_dataframe(CCCs)\n",
    "print(DFccc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "confidence_interval_width = 0.01\n",
    "confidence_interval_prob = 0.9\n",
    "    \n",
    "def plot_CCC_DF(DF, doc_ind=None, d=3):\n",
    "    global SAVE_FIGURES_FOR_LATEX\n",
    "    print('Training set sizes = ',\n",
    "          DF.training_set_size.min(),\n",
    "          '--',\n",
    "          DF.training_set_size.max()\n",
    "         )\n",
    "    if doc_ind is not None:\n",
    "        DF = DF.loc[DF.doc_ind == doc_ind, :]\n",
    "    n_docs = DF.doc_ind.nunique()\n",
    "    cp = sns.color_palette('hls', n_docs, desat=0.9)\n",
    "    handle = sns.scatterplot(\n",
    "        data=DF,\n",
    "        x='training_set_size',\n",
    "        y='classifier_accuracy',\n",
    "        hue='doc_ind',\n",
    "        legend=None,\n",
    "        palette=cp,\n",
    "    \n",
    "    )\n",
    "   \n",
    "    # curve for all the data\n",
    "    d=3\n",
    "    fit_model = 'gyorfi'\n",
    "    x = DF.training_set_size.values.astype(np.double)\n",
    "    ks = transform_n_to_k_for_knn(x, fit_model, d=d)\n",
    "    y = DF.classifier_accuracy.values\n",
    "    m, C = asymptotic_curve(ks, y)\n",
    "    print(f'm={m} C={C}')\n",
    "    \n",
    "    # bootstrap for ub\n",
    "    boot_res = compute_bootstrapped_upper_bound(x, d, fit_model, y,\n",
    "                                 confidence_interval_prob,\n",
    "                                 confidence_interval_width)\n",
    "    samples = boot_res['bootstrap_samples'] \n",
    "    \n",
    "    ub = boot_res['ub']\n",
    "    base = config.SAMPLES_BASE\n",
    "    xx = np.logspace(np.log(np.min(x))/np.log(base),\n",
    "                     np.log(np.max(x))/np.log(base),\n",
    "                    base=base)\n",
    "    kks = transform_n_to_k_for_knn(xx, fit_model, d=d)\n",
    "    plt.plot(xx, m+C*kks, '-g')\n",
    "    \n",
    "    labeled_axhline(ub, 'U.B.', 'k', handle)\n",
    "    labeled_axhline(m, '$E[C_\\infty]$', 'g', handle, linestyle='--')\n",
    "    labeled_axhline(pc, '$C_\\infty^*$', 'r', handle)\n",
    "    \n",
    "    plt.xticks(x, ['$2^{%s}$'%'{:}'.format(int(np.log(xx)/np.log(2))) for xx in x],\n",
    "              rotation=30)\n",
    "    \n",
    "    if SAVE_FIGURES_FOR_LATEX:\n",
    "        plt.xlabel('Training Set Size')\n",
    "        plt.ylabel('P[correct]')\n",
    "    \n",
    "    ax2 = handle.twiny()\n",
    "    ax2.set_xlim(0, 100.0)\n",
    "    ax2.set_xticks([])\n",
    "    sns.distplot(a=samples,\n",
    "                 bins=30,\n",
    "                 hist=True,\n",
    "                 hist_kws={'alpha':0.30},\n",
    "                 norm_hist=True,\n",
    "                 kde=False,\n",
    "                 kde_kws={'linestyle':':', 'alpha':0.75},\n",
    "                 rug=False,\n",
    "                 vertical=True,\n",
    "                 color='g',\n",
    "                ax=ax2)\n",
    "\n",
    "    if SAVE_FIGURES_FOR_LATEX:\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(FIGURES_PATH, 'experiment_1_bootstrap_visualization.png'))\n",
    "\n",
    "\n",
    "    \n",
    "# call the function\n",
    "plot_CCC_DF(DFccc, 0)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
